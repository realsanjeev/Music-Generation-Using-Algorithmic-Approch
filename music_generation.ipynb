{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Generation using Algo Approch\n",
    "I utilized a modified version of the 16x16 tone matrix concept to generate music. Specifically, I processed an image and used it as a switch to activate specific elements in the tone matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import music21 as m21\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aI3R3GFuPcmR",
    "outputId": "6584534b-78c9-44e1-ccfd-adfb3ec0f7db"
   },
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv2.imread('/workspaces/Music-Generation-Using-Algorithmic-Approch/Warren-Buffett-On-Rules.jpg')\n",
    "\n",
    "# Resize the image to 16x16 pixels\n",
    "resized_img = cv2.resize(img, (SEQ_LEN, 16))\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# for working with different color scale, split image into b, g, r separately\n",
    "b, r, g = cv2.split(resized_img)\n",
    "print(f\"Shape of one space image: {b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intensity_columnwise(img, seq_len=16, approach='max'):\n",
    "    \"\"\"\n",
    "    Get the intensity values of the resized image.\n",
    "\n",
    "    Args:\n",
    "        img: numpy array\n",
    "            The resized image as a 2D array with only one color scale.\n",
    "        seq_len: int, optional (default: 16)\n",
    "            The length of the generated music sequence. The width of the image is divided into this many segments.\n",
    "        approach: str, optional (default: 'max')\n",
    "            The approach to use when mapping pixel intensity to musical notes. 'max' uses the maximum pixel intensity,\n",
    "            while 'average' uses the average intensity.\n",
    "\n",
    "    Returns:\n",
    "        column_index: list\n",
    "            A list of the indices of the maximum (or average) intensity value in each column of the image.\n",
    "    \"\"\"\n",
    "    intensity_values = resized_img.flatten()\n",
    "\n",
    "    # Transpose the intensity values to get the values column-wise\n",
    "    intensity_values_column_wise = [intensity_values[i::seq_len] for i in range(seq_len)]\n",
    "\n",
    "    column_index = []\n",
    "    \n",
    "    # Print the index of the intensity values column-wise\n",
    "    for i, col in enumerate(intensity_values_column_wise):\n",
    "        if approach == 'max':\n",
    "            indices = np.where(col == col.max())[0].tolist()\n",
    "        elif approach == 'min':\n",
    "            indices = np.where(col == col.min())[0].tolist()\n",
    "        else:\n",
    "            print(f\"approch can be 'min' or 'max'. \\nPlease Check your code where approach={approach} is invalid\")\n",
    "        column_index.append(indices)\n",
    "        print(f'Column {i}: {col} and maxindex: {indices}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot images with separate color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKVtNY2llL_L"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "images_color_space = (b, g, r)\n",
    "image_label = ['Blue', 'Green', 'Red']\n",
    "for index in range(3):\n",
    "    plt.subplot(1, 3, index+1)\n",
    "    plt.title(f\"{image_label[index]} Color Space\")\n",
    "    plt.imshow(images_color_space[index], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tone matrix Configuration\n",
    "The Tone matrix is a 2D matrix where the horizontal axis represents time and the vertical axis represents frequency. As we move from bottom to top on the vertical axis, the frequency increases. Similarly, as we move from left to right on the horizontal axis, time increases. The matrix consists of 16 fixed notes, where each note is assigned a unique row ranging from the lower frequency note C3 to the upper frequency note C6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCdZKkfuSmXP"
   },
   "outputs": [],
   "source": [
    "# make 16x16 tone matrix\n",
    "switch = np.zeros((16, SEQ_LEN), dtype='object')\n",
    "notes = ['C6', 'A5', 'G5', 'F5', 'D5', 'C5', 'A4', 'G4',\n",
    "        'F4', 'D4', 'C4', 'A3', 'G3', 'F3', 'D3', 'C3']\n",
    "for i in range(16):\n",
    "  switch[i, :] = notes[i]\n",
    "print(f\"Tone matrix shape: {switch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only one switched is allowed in a time.\n",
    "If there are more switches that are to be opened in column-wise, then switch with least frequency is played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "ih7P5G6KQK2r",
    "outputId": "276344cf-5b91-48bc-df80-09f0e92fc6f4"
   },
   "outputs": [],
   "source": [
    "bw_image = np.zeros((16, 16), dtype='uint8')\n",
    "for i, index_col in enumerate(column_index):\n",
    "  if len(index_col) == 1:\n",
    "    col = index_col[-1]\n",
    "    bw_image[i][col] = 255\n",
    "\n",
    "bw_image = bw_image.T\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(bw_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qz46AnV7jpLW"
   },
   "outputs": [],
   "source": [
    "def construct_melody(image, tone_matrix, instrument='Piano', seq_len=16):\n",
    "    \"\"\"\n",
    "    Generate a Music21 Stream object.\n",
    "\n",
    "    Args:\n",
    "        image: numpy array or list, shape (16, seq_len)\n",
    "            The image that serves as the basis for the melody.\n",
    "        tone_matrix: numpy array or list, shape (16, seq_len)\n",
    "            The tone matrix that corresponds to the image.\n",
    "        instrument: str, optional (default: 'Piano')\n",
    "            The instrument to use when creating the melody.\n",
    "        seq_len: int, optional (default: 16)\n",
    "            The length of the melody, in number of notes.\n",
    "\n",
    "    Returns:\n",
    "        A Music21 Stream object representing the generated melody.\n",
    "    \"\"\"\n",
    "    stream_algo = m21.stream.Stream()\n",
    "    instrument_func = m21.instrument.fromString(instrument)\n",
    "    stream_algo.insert(0.0, instrument_func)\n",
    "    offset = 0\n",
    "    for y in range(seq_len):\n",
    "        add = ''\n",
    "        for x in range(16):\n",
    "            if (image[x][y] != 0):\n",
    "                temp = tone_matrix[x][y]\n",
    "                add = add + ' ' + temp\n",
    "            stream_algo.insertIntoNoteOrChord(offset, m21.chord.Chord(add))\n",
    "        if (len(add.split()) == 1):\n",
    "            offset += 0.5\n",
    "            print(f\"{offset} offset has Chord: {add}\")\n",
    "        else: \n",
    "            offset += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save in midi format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "MxPm7jiHicNy",
    "outputId": "731575d3-7927-49cf-ec73-5c6f1f00221e"
   },
   "outputs": [],
   "source": [
    "stream_algo = construct_melody(image=bw_image, tone_matrix=switch, seq_len=SEQ_LEN)\n",
    "stream_algo.show('text')\n",
    "stream_algo.write('midi', 'algo_one_note_q.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sEx-KG9n1UT"
   },
   "source": [
    "# second bw_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mIwm9aI7n_D_",
    "outputId": "8af0f7da-74f7-4c60-c190-203f3d67f714"
   },
   "outputs": [],
   "source": [
    "bw_image = np.zeros((16, 16), dtype='uint8')\n",
    "for column_index in enumerate():\n",
    "for index, col in column_index:\n",
    "# print(index_col)\n",
    "if len(index_col) == 1:\n",
    "  col = index_col[0]\n",
    "  bw_image[i][col] = 255\n",
    "elif len(index_col) == 2:\n",
    "  print(index_col)\n",
    "  col = index_col[0]\n",
    "  col2 = index_col[1]\n",
    "  bw_image[i][col] = 255\n",
    "  bw_image[i][col2] = 255\n",
    "elif len(index_col) > 2:\n",
    "  rand_index = sorted(np.random.randint(0, len(index_col), size=2))\n",
    "  print(rand_index)\n",
    "  if i % 2 == 0:\n",
    "      col1 = index_col[-1]\n",
    "  else: \n",
    "      col1 = index_col[-2]\n",
    "  col2 = rand_index[-1]\n",
    "  col3 = rand_index[-2]\n",
    "  bw_image[i][col1] = 255\n",
    "  bw_image[i][col2] = 255\n",
    "  # bw_image[i][col3] = 255\n",
    "\n",
    "# transpose bw_image to that of tone matrix dimension\n",
    "bw_image = bw_image.T\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(bw_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DeCMYDuo-1-",
    "outputId": "101c6d18-01c6-4b1b-bd30-2a376540b6a0"
   },
   "outputs": [],
   "source": [
    "# generating midi file\n",
    "stream_algo = m21.stream.Stream()\n",
    "instrument = m21.instrument.fromString('Violin')\n",
    "stream_algo.insert(0.0, instrument)\n",
    "offset = 0\n",
    "for y in range(16):\n",
    "    add = ''\n",
    "    for x in range(16):\n",
    "        if (bw_image[x][y] == 255):\n",
    "            temp = switch[x][y]\n",
    "            add = add+' '+temp\n",
    "    # if (add):\n",
    "    stream_algo.insertIntoNoteOrChord(offset, m21.chord.Chord(add))\n",
    "    if (len(add.split()) == 1):\n",
    "        offset += 0.5\n",
    "        print('single',offset)\n",
    "    else: \n",
    "        offset += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "BtXCQUr7S2Ks",
    "outputId": "6d9db57c-852f-4c30-e6e6-448ca6902135"
   },
   "outputs": [],
   "source": [
    "stream_algo.show('text')\n",
    "stream_algo.write('midi', 'algo_2s.midi')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
