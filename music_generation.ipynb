{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Generation using Algo Approch\n",
    "I utilized a modified version of the 16x16 tone matrix concept to generate music. Specifically, I processed an image and used it as a switch to activate specific elements in the tone matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies\n",
    "For image manipulation, OpenCV library has been utilized.\n",
    "To process symbolic music representation, Music21 library has been implemented.\n",
    "For carrying out array and matrix operations during the process, NumPy library has been used.\n",
    "To display and save high-quality images in higher dimensions, Matplotlib library has been incorporated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import music21 as m21\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aI3R3GFuPcmR",
    "outputId": "6584534b-78c9-44e1-ccfd-adfb3ec0f7db"
   },
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv2.imread('Warren-Buffett-On-Rules.jpg')\n",
    "\n",
    "# Resize the image to 16x16 pixels\n",
    "resized_img = cv2.resize(img, (SEQ_LEN, 16))\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# for working with different color scale, split image into b, g, r separately\n",
    "b, r, g = cv2.split(resized_img)\n",
    "print(f\"Shape of one space image: {b.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting intensity information column-wise\n",
    "The algorithm extracts the intensity information from the image column-wise. For each column, it calculates either the maximum intensity or the minimum intensity value according to user choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intensity_columnwise(resized_img, seq_len=16, approach='max'):\n",
    "    \"\"\"\n",
    "    Get the intensity values of the resized image.\n",
    "\n",
    "    Args:\n",
    "        resized_img: numpy array\n",
    "            The resized image as a 2D array with only one color scale.\n",
    "        seq_len: int, optional (default: 16)\n",
    "            The length of the generated music sequence. The width of the image is divided into this many segments.\n",
    "        approach: str, optional (default: 'max')\n",
    "            The approach to use when mapping pixel intensity to musical notes. 'max' uses the maximum pixel intensity,\n",
    "            while 'average' uses the average intensity.\n",
    "\n",
    "    Returns:\n",
    "        column_index: list\n",
    "            A list of the indices of the maximum (or average) intensity value in each column of the image.\n",
    "    \"\"\"\n",
    "    intensity_values = resized_img.flatten()\n",
    "    print(f'Shape of intensity_values: {intensity_values.shape} and resized image_shape: {resized_img.shape}')\n",
    "\n",
    "    # Transpose the intensity values to get the values column-wise\n",
    "    intensity_values_column_wise = [intensity_values[i::seq_len] for i in range(seq_len)]\n",
    "\n",
    "    column_index = []\n",
    "    \n",
    "    # Print the index of the intensity values column-wise\n",
    "    for i, col in enumerate(intensity_values_column_wise):\n",
    "        print(f'Index: {i} and Length of col: {len(col)}')\n",
    "        if approach == 'max':\n",
    "            indices = np.where(col == col.max())[0].tolist()\n",
    "        elif approach == 'min':\n",
    "            indices = np.where(col == col.min())[0].tolist()\n",
    "        else:\n",
    "            print(f\"approch can be 'min' or 'max'. \\nPlease Check your code where approach={approach} is invalid\")\n",
    "        column_index.append(indices)\n",
    "        print(f'Column {i}: {col} and maxindex: {indices}')\n",
    "    return column_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_intensity_list = get_intensity_columnwise(b, seq_len=SEQ_LEN)\n",
    "# min_intensity_list = get_intensity_columnwise(b, seq_len=16, approach='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_intensity_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot images with separate color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKVtNY2llL_L"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,SEQ_LEN))\n",
    "images_color_space = (b, g, r)\n",
    "image_label = ['Blue', 'Green', 'Red']\n",
    "for index in range(3):\n",
    "    plt.subplot(1, 3, index+1)\n",
    "    plt.title(f\"{image_label[index]} Color Space\")\n",
    "    plt.imshow(images_color_space[index], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tone matrix Configuration\n",
    "The Tone matrix is a 2D matrix where the horizontal axis represents time and the vertical axis represents frequency. As we move from bottom to top on the vertical axis, the frequency increases. Similarly, as we move from left to right on the horizontal axis, time increases. The matrix consists of 16 fixed notes, where each note is assigned a unique row ranging from the lower frequency note C3 to the upper frequency note C6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCdZKkfuSmXP"
   },
   "outputs": [],
   "source": [
    "# make 16x16 tone matrix\n",
    "switch = np.zeros((16, SEQ_LEN), dtype='object')\n",
    "notes = ['C6', 'A5', 'G5', 'F5', 'D5', 'C5', 'A4', 'G4',\n",
    "        'F4', 'D4', 'C4', 'A3', 'G3', 'F3', 'D3', 'C3']\n",
    "for i in range(16):\n",
    "  switch[i, :] = notes[i]\n",
    "print(f\"Tone matrix shape: {switch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Switch configuration\n",
    "If there are more switches that are to be opened in column-wise, then switch with least frequency is played. Here, column with highest index has lowest frequency\n",
    "\n",
    "The pure black and white image is constructed by interchanging rows and columns for easier calculation. It has dimension Nx16. To get image with dimension equal to tone matrix, we transpose the array to get dimension 16xN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "ih7P5G6KQK2r",
    "outputId": "276344cf-5b91-48bc-df80-09f0e92fc6f4"
   },
   "outputs": [],
   "source": [
    "def construct_switch_config(intensity, seq_len=16, config='s'):\n",
    "    '''\n",
    "    Constructs a black and white image based on the given intensity values and configuration.\n",
    "\n",
    "    Args:\n",
    "        intensity: np.array or list -> A list containing a list of intensity indices.\n",
    "        seq_len: int -> The length of the time axis. Default value is 16.\n",
    "        config: str -> Configuration for the switch matrix. Possible values are:\n",
    "                's' (single): Only one note can be activated in a column at a time.\n",
    "                'two': A maximum of two notes can be played at a time.\n",
    "                'three': A maximum of three notes can be played at a time.\n",
    "                'all': No limit to the number of notes that can be played at a time. (can be from 1 to 16)\n",
    "\n",
    "    Result:\n",
    "        bw_image: np.array -> A 2D array representing the black and white image where white represents the ON state \n",
    "                              and black represents the OFF state.\n",
    "    '''\n",
    "    bw_image = np.zeros((16, 16), dtype='uint8')\n",
    "    if config.lower() == 's' or config.lower()=='single':\n",
    "        for i, index_col in enumerate(intensity):\n",
    "            col = index_col[-1]\n",
    "            bw_image[i][col] = 255\n",
    "            \n",
    "    if config.lower()=='two':\n",
    "        for i, index_col in enumerate(intensity):\n",
    "            col = index_col[-1]\n",
    "            bw_image[i][col] = 255\n",
    "            try:\n",
    "                col = index_col[-2]\n",
    "                bw_image[i][col] \n",
    "            except IndexError:\n",
    "                continue\n",
    "        \n",
    "    if config.lower == 'all':\n",
    "        for i, index_col in enumerate(intensity):\n",
    "            for col in index_col:\n",
    "                bw_image[i][col] = 255\n",
    "    bw_image = bw_image.T\n",
    "    return bw_image\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(bw_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating melody\n",
    "The tone matrix is configured with a switch setting (black and white) to produce the melody."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qz46AnV7jpLW"
   },
   "outputs": [],
   "source": [
    "def construct_melody(image, tone_matrix, instrument='Piano', seq_len=16):\n",
    "    \"\"\"\n",
    "    Generate a Music21 Stream object.\n",
    "\n",
    "    Args:\n",
    "        image: numpy array or list, shape (16, seq_len)\n",
    "            The image that serves as the basis for the melody.\n",
    "        tone_matrix: numpy array or list, shape (16, seq_len)\n",
    "            The tone matrix that corresponds to the image.\n",
    "        instrument: str, optional (default: 'Piano')\n",
    "            The instrument to use when creating the melody.\n",
    "        seq_len: int, optional (default: 16)\n",
    "            The length of the melody, in number of notes.\n",
    "\n",
    "    Returns:\n",
    "        A Music21 Stream object representing the generated melody.\n",
    "    \"\"\"\n",
    "    stream_algo = m21.stream.Stream()\n",
    "    instrument_func = m21.instrument.fromString(instrument)\n",
    "    stream_algo.insert(0.0, instrument_func)\n",
    "    offset = 0\n",
    "    for y in range(seq_len):\n",
    "        add = ''\n",
    "        for x in range(16):\n",
    "            if (image[x][y] != 0):\n",
    "                temp = tone_matrix[x][y]\n",
    "                add = add + ' ' + temp\n",
    "            stream_algo.insertIntoNoteOrChord(offset, m21.chord.Chord(add))\n",
    "        if (len(add.split()) == 1):\n",
    "            offset += 0.5\n",
    "            print(f\"{offset} offset has Chord: {add}\")\n",
    "        else: \n",
    "            offset += 1\n",
    "    return stream_algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save in midi format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "MxPm7jiHicNy",
    "outputId": "731575d3-7927-49cf-ec73-5c6f1f00221e"
   },
   "outputs": [],
   "source": [
    "stream_algo = construct_melody(image=bw_image, tone_matrix=switch, seq_len=SEQ_LEN)\n",
    "stream_algo.show('text')\n",
    "stream_algo.write('midi', 'algo_one_note_q.mid')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
